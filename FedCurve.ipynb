{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing packages\n",
    "#%pip install panel --user\n",
    "#pip install panel==0.12 --user\n",
    "#!pip install hvplot==0.7.3 --user\n",
    "#conda install -c pyviz panel \n",
    "#conda install -c pyviz hvplot\n",
    "#conda install -c conda-forge hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from KalshiClientsBaseV2 import ExchangeClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "import uuid\n",
    "import urllib.request,urllib.parse,urllib.error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.pyplot import figure, xticks\n",
    "from ipywidgets import widgets, interact, interactive, fixed, interact_manual,GridspecLayout\n",
    "from scipy.interpolate import CubicSpline\n",
    "import ipywidgets as widgets\n",
    "import User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exchange_active': True, 'trading_active': True}\n"
     ]
    }
   ],
   "source": [
    "username = User.username\n",
    "password = User.password\n",
    "demo_api_base = 'https://trading-api.kalshi.com/trade-api/v2'\n",
    "\n",
    "exchange_client = ExchangeClient(demo_api_base, username, password)\n",
    "print(exchange_client.get_exchange_status())\n",
    "\n",
    "lookback = User.lookback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(tickr, params, func, content_name,max_pages = None):\n",
    "    '''\n",
    "    returns all history cleaned dataframe\n",
    "    content_name is the desired string from the json output (either 'history' or 'trades')\n",
    "    sometimes people want to limit max_pages to avoid getting too many data\n",
    "    '''\n",
    "    \n",
    "    histories = []\n",
    "    content = func(**params)\n",
    "    histories.append(pd.DataFrame(content[content_name]))\n",
    "    params['cursor'] = content['cursor']\n",
    "\n",
    "    if max_pages is None:\n",
    "        while content['cursor'] is not None and content['cursor'] !='':\n",
    "            content = func(**params)\n",
    "            histories.append(pd.DataFrame(content[content_name]))\n",
    "            params['cursor'] = content['cursor']\n",
    "    # if max_pages is specified, then I only retrieve at most max_pages pages\n",
    "    else:\n",
    "        for i in tqdm(range(max_pages-1)):\n",
    "            content = func(**params)\n",
    "            histories.append(pd.DataFrame(content[content_name]))\n",
    "            params['cursor'] = content['cursor']\n",
    "            if content['cursor'] is None or content['cursor'] =='':\n",
    "                break\n",
    "                \n",
    "    histories_df = pd.concat(histories)\n",
    "    try: #some calls may contain a 'ts' column - we convert that into normal datetime\n",
    "        histories_df['Date']= histories_df['ts'].apply(lambda x: datetime.fromtimestamp(x).date())\n",
    "    except:\n",
    "        p = 1 #not do anything\n",
    "\n",
    "    return histories_df\n",
    "\n",
    "def contract_history(tickr, min_ts = None, max_ts = None,max_pages = None):\n",
    "    '''\n",
    "    Returns all contract history cleaned dataframe without duplicates.\n",
    "    Analogous to exchange_client.get_market_history()\n",
    "    '''\n",
    "    params =     {\n",
    "                         'limit': 100, #100 is the max limit per page\n",
    "                         'min_ts' : min_ts,\n",
    "                         'max_ts':max_ts,\n",
    "                        'cursor':None,\n",
    "    'ticker':tickr}\n",
    "\n",
    "    contract_histories_df = get_content(tickr = tickr, params = params, func = exchange_client.get_market_history, content_name = 'history',max_pages = max_pages)\n",
    "    \n",
    "    return contract_histories_df\n",
    "\n",
    "def trade_history(tickr, min_ts = None, max_ts = None,max_pages=None):\n",
    "    '''\n",
    "    Returns all trade history cleaned dataframe \n",
    "    Analogous to exchange_client.get_trades()\n",
    "    Outputs df columns: yesprice,yesbid,yesask,nobid,noask, volume,openinterest,ts,Time\n",
    "    '''\n",
    "    params =     {\n",
    "                         'limit': 100, #100 is the max limit per page\n",
    "                         'min_ts' : min_ts,\n",
    "                         'max_ts':max_ts,\n",
    "                        'cursor':None,\n",
    "    'ticker':tickr}\n",
    "    trade_histories_df = get_content(tickr = tickr, params = params, func = exchange_client.get_trades, content_name = 'trades',max_pages=max_pages)\n",
    "    \n",
    "    return trade_histories_df\n",
    "\n",
    "def specified_markets(min_close_ts = None, max_close_ts = None,event_ticker = None,series_ticker = None,tickers = None, status = None):\n",
    "    '''\n",
    "    Specify some parameters (time/event/series/status),returns a df of all related contracts and related info.\n",
    "    Analogous to exchange_client.get_markets()\n",
    "    '''\n",
    "    markets_params =     {\n",
    "                         'limit': 100, #100 is the max limit per page\n",
    "                         'min_close_ts' : min_close_ts,\n",
    "                         'max_close_ts':max_close_ts,\n",
    "                         'event_ticker':event_ticker,\n",
    "                         'series_ticker':series_ticker,\n",
    "                         'cursor':None,\n",
    "                         'tickers':tickers,\n",
    "                         'status' : status}\n",
    "    markets = []\n",
    "    market = exchange_client.get_markets(**markets_params)\n",
    "    markets.append(pd.DataFrame(market['markets']))\n",
    "    markets_params['cursor'] = market['cursor']\n",
    "\n",
    "    while market['cursor'] !='' and market['cursor'] is not None:\n",
    "        market = exchange_client.get_markets(**markets_params)\n",
    "        markets.append(pd.DataFrame(market['markets']))\n",
    "        markets_params['cursor'] = market['cursor']\n",
    "        #print(markets_params['cursor'])\n",
    "    \n",
    "    markets_df= pd.concat(markets)\n",
    "    return markets_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for setting up default meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_close(actual_FOMC):\n",
    "    '''\n",
    "    Retuns the latest meeting and rate as a tuple e.g.('22DEC',425) \n",
    "    '''\n",
    "    max_date = datetime(2010,1,1)\n",
    "    for key,value in actual_FOMC.items():\n",
    "        if value[0]>max_date:\n",
    "            max_date = value[0]\n",
    "            meeting = key\n",
    "            bps = value[1]\n",
    "    return (meeting,bps)\n",
    "\n",
    "def unsettled_contracts(contract_type = 'FED'):\n",
    "    '''\n",
    "    Function for getting all unsettled contract IDs about that event\n",
    "    '''\n",
    "    df = specified_markets(event_ticker = contract_type,status = 'open')\n",
    "    #filitering to make sure we only take our desired contracts with series ID like 'FED-23FEB'\n",
    "    filtered_df = df[(df['event_ticker'].str[:4]=='FED-') & (df['event_ticker'].str[4:6].str.isnumeric()) & (df['event_ticker'].str.len()==9)]\n",
    "    #display in timeorder e.g. ['23FEB','23MAR'...]\n",
    "    contracts = list(filtered_df.event_ticker.unique()) \n",
    "    contracts.reverse() \n",
    "    \n",
    "    return contracts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for working with df of historical implied rates for different meetings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow: build_df -> build_df_each_rate -> cum_df  -> discrete_df -> meetings_implied_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(contract_id, category,lookback):\n",
    "    '''\n",
    "    Function that returns daily closing price of that contract in a dataframe\n",
    "    Category refers to the type/strike e.g.\"5.00%\"\n",
    "    Requires a lookback to specify earliest time otherwise the function will collect too much data since the launch of the contract \n",
    "    Output has index Time, columns [volume, open_interest, price, spread] \n",
    "    Example of calling the function: build_df(contract_id = 'FED-23MAY-T5.00',category = '5.00',lookback = 30) \n",
    "    '''\n",
    "    \n",
    "    #Current date\n",
    "    current_time = datetime.today()\n",
    "    current_date = current_time.date()\n",
    "    \n",
    "    start_time = int((current_time - dt.timedelta(days=lookback)).timestamp()) \n",
    "    \n",
    "    df = contract_history(tickr = contract_id, min_ts = start_time)\n",
    "    #original df has columns: yesprice,yesbid,yesask,nobid,noask, volume,openinterest,ts,Time\n",
    "    df['price'] = (df['yes_bid'] + df['yes_ask'])/2\n",
    "    df['spread'] = df['yes_ask'] - df['yes_bid']\n",
    "    df = df.drop(['yes_bid','yes_ask','yes_price','no_bid','no_ask'],axis = 1)\n",
    "    \n",
    "    #Get only daily closing price with date column. There may be multiple ts a day. only use the last one.\n",
    "    df['Month/Day'] = df['Date'].apply(lambda x: str(x.month)+'/' + str(x.day))\n",
    "    df['closing'] = np.where(df['Month/Day']!=df['Month/Day'].shift(-1),1,0)\n",
    "    df.iloc[-1,df.columns.get_loc('closing')] = 1  #filling the last timestamp also to 1\n",
    "    df_target =df[df.closing == 1]\n",
    "    df_target = df_target.reset_index(drop = True)\n",
    "    \n",
    "    try:\n",
    "    #add in today's date in case there is no observation today\n",
    "        last_date = df_target['Date'][df_target.shape[0]-1]\n",
    "        if last_date != current_date:\n",
    "            df_target = df_target.append({'Date':current_date},ignore_index=True)  \n",
    "    except:\n",
    "        #we get an empty data frame, so do nothing (error occurs because df_target['Time'] has no length#\n",
    "        1\n",
    "        \n",
    "    df_target['Category'] = category\n",
    "    df_target = df_target.drop(['Month/Day','closing','ts'],axis = 1)\n",
    "\n",
    "    ##autofill missing date value same as last observed value, making sure there's data on every day\n",
    "    r = pd.date_range(start=df_target.Date.min(), end=df_target.Date.max())\n",
    "    df_target = df_target.set_index('Date').reindex(r).fillna(method = 'ffill').rename_axis('Date').reset_index()\n",
    "    \n",
    "    return df_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bps(string):\n",
    "    return float(string.strip('%'))*100\n",
    "\n",
    "def build_df_each_rate(contract_ids,categories,lookback):\n",
    "    '''\n",
    "    For one specific meeting, takes in a list of ids and list of categories(i.e. 5.00%)\n",
    "    Applies build_df\n",
    "    Return a dictionary of dfs, each df contains daily info of that specific contract\n",
    "    '''\n",
    "    \n",
    "    contracts = {}\n",
    "    for contract_id,category in zip(contract_ids,categories):\n",
    "        contracts[category] = build_df(contract_id,category,lookback = lookback)\n",
    "    return contracts\n",
    "\n",
    "def cumulative_df(contracts):\n",
    "    '''\n",
    "    takes in dic of contracts df for specific meeting, (output of build_df_each_rate)\n",
    "    returns a df representing cumulative possibilities across time\n",
    "    Each row is a date, each column shows the price for the dif rates\n",
    "    month,year allows us to manually adjust for erroneous data\n",
    "    '''\n",
    "    \n",
    "    #Current date\n",
    "    current_time = datetime.today()\n",
    "    current_date = current_time.date()\n",
    "    \n",
    "    #initiate an empty df with date index\n",
    "    final_df = pd.DataFrame({'Date': []})\n",
    "    categories = list(contracts.keys())  #list of ['>3.00%, >3.25%', etc]\n",
    "   \n",
    "    #Sometimes different contracts in the same series will open at different times\n",
    "    #we therefore try to use the date of the earliest contract as benchmark for our date index\n",
    "    early_date = current_date\n",
    "    earliest_contract = categories[0] \n",
    "    for key,df in contracts.items():\n",
    "        if df.loc[0].Date < early_date:\n",
    "            early_date = df.loc[0].Date #updating the earliest date \n",
    "            earliest_contract = key  #updating the earliest contract\n",
    "    final_df['Date'] = contracts[earliest_contract].Date   #assumed we used the date available for the contract date\n",
    "    \n",
    "    #joining the different contracts for that series on Date\n",
    "    for bp,df in contracts.items():\n",
    "        final_df = pd.merge(final_df,df[['Date','price']],on = 'Date',how='left')\n",
    "        bp = bp[1:6]   #Some contracts are titled '>4.25% :: +25bp hike' etc. We only want the the numbers\n",
    "        final_df = final_df.rename(columns = {'price':bp} )\n",
    "        \n",
    "    #missing values are filled with 0 - unable to trade\n",
    "    final_df = final_df.interpolate().fillna(0).set_index('Date').div(100)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def discrete_df(cumulative_df,month,year):\n",
    "    '''\n",
    "    Create new df for discrete rather than cumulative probabilities\n",
    "    Output is a df with date as index and 1 column of implied rates on that date\n",
    "    '''\n",
    "    discrete_df = cumulative_df.copy()\n",
    "        \n",
    "    for ind, column in enumerate(cumulative_df.columns):\n",
    "        #calculates the discrete probabilities by subtracting adjacent cumulative probabilities\n",
    "        if ind < len(cumulative_df.columns)-1: \n",
    "            discrete_df[column] = cumulative_df[column] - cumulative_df.iloc[:,ind+1]\n",
    "            \n",
    "    rates=[]\n",
    "    for rate in cumulative_df.columns:\n",
    "        rates.append(to_bps(rate))\n",
    "\n",
    "    def get_weighted(values):\n",
    "        '''\n",
    "        Function for calculating weighted avg\n",
    "        '''\n",
    "        #one series my have 0 price for lower, less liquid strikes\n",
    "        #which leads to negative values in our discrete probabilities.\n",
    "        #hence when calculating the weighted avg, we convert these negatives to 0\n",
    "        values = [max(0,val) for val in values ]\n",
    "        try: \n",
    "            avg = np.average(a = rates,weights = values)\n",
    "        except:\n",
    "            avg = 0\n",
    "        return avg\n",
    "\n",
    "    #Calculate implied rates with weighted average\n",
    "    discrete_df['Implied_rate'] = discrete_df.apply(get_weighted,axis = 1).round(2)\n",
    "    kalshi_df = discrete_df['Implied_rate'].to_frame(name = f'{year}{month}')\n",
    "    \n",
    "    actual_FOMC_df = User.actual_FOMC_df\n",
    "    \n",
    "    #updating settled markets on realized Fed Funds rates\n",
    "    for meeting in kalshi_df.columns:\n",
    "        #the actual FFR release date: Real World Meeting date +1 (e.g. Rate announced on Nov 14th, \n",
    "        #update will start on Nov 15th)\n",
    "        try:\n",
    "            update_date = actual_FOMC_df.loc[meeting,'Update Date']   \n",
    "            #updating any dates on/after that date\n",
    "            kalshi_df.loc[update_date:,meeting] = actual_FOMC_df.loc[meeting,'FFR in bps']\n",
    "        except KeyError: #this market hasn't settled yet (i.e. we don't have the meeting in the actual_FOMC_df data frame)\n",
    "            pass  #we don't do anything\n",
    "        \n",
    "    return kalshi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meetings_implied_df(series_ids,lookback):\n",
    "    '''\n",
    "    Function for getting historical implied rates daily for different meetings in my [series ids] list\n",
    "    e.g. series_ids = ['FED-22DEC','FED-23FEB','FED-23MAR']\n",
    "    Returns a df with each row being implied rates on that date, and each column being the different meetings\n",
    "    '''\n",
    "    \n",
    "    series_dfs = {}\n",
    "    for series_id in series_ids:\n",
    "        #get df for each contract in the series in order to retrieve all tickers for that series\n",
    "        series_content_df = specified_markets(series_ticker= series_id)\n",
    "        #for each series, get dictionary of df for specific contracts\n",
    "        try:\n",
    "            contracts = build_df_each_rate(contract_ids = series_content_df.ticker.tolist(), categories = series_content_df.subtitle.tolist(),lookback = lookback) \n",
    "        except:\n",
    "            raise ValueError(f\"each element in series_ids need to be formatted like: 'FED-YYMMM', or need longer lookback period\")\n",
    "\n",
    "        #we put the dictionary into another dictionary\n",
    "        series_dfs[series_id] = contracts\n",
    "\n",
    "    meetings = {}\n",
    "    for meeting,historical_rates in series_dfs.items():\n",
    "        cum_df = cumulative_df(historical_rates).iloc[:,::-1]\n",
    "        imp_rates = discrete_df(cum_df,month = meeting[-3:], year =meeting[-5:-3]) #naming the columns\n",
    "        meetings[meeting] = imp_rates\n",
    "    meetings_implied_df = pd.concat(meetings.values(),axis = 1).fillna(0)\n",
    "    \n",
    "    meetings_implied_df = meetings_implied_df.round().astype(int) #round up/down decimals \n",
    "    meetings_implied_df.replace(0, np.nan, inplace=True)  #convert all 0s to nans (contract isn't open yet)\n",
    "    \n",
    "    return meetings_implied_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotting(meetings_implied_df,date):\n",
    "    '''\n",
    "    Takes in a meetings_implied_df and datelist(date slider), plots 2 yield curves\n",
    "    Also returns data table of all implied rates for different meetings on the two input days     \n",
    "    '''\n",
    "    \n",
    "    meetings = np.array(meetings_implied_df.columns)\n",
    "    less_than_two_contracts_2 = False\n",
    "    less_than_two_contracts_1 = False\n",
    "\n",
    "    \n",
    "    date_2 = date[-1]\n",
    "    date_1 = date[0]\n",
    "    unfiltered_row_2 = np.array(meetings_implied_df.loc[date_2])\n",
    "    unfiltered_row_1 = np.array(meetings_implied_df.loc[date_1])\n",
    "    \n",
    "    row_2 = unfiltered_row_2[~np.isnan(unfiltered_row_2)]   # some days not all contracts are active, this is required so that our smoothing can work properly\n",
    "    row_1 = unfiltered_row_1[~np.isnan(unfiltered_row_1)]   # some days not all contracts are active\n",
    "   \n",
    "    \n",
    "    str_to_dt = np.vectorize(lambda x: datetime.strptime(x, '%y%b'))\n",
    "    meeting_dates = str_to_dt(meetings) #all meeting dates \n",
    "\n",
    "    \n",
    "    meeting_timedelta_from_start = (meeting_dates-meeting_dates[0])\n",
    "    dt_to_days = np.vectorize(lambda x: x.days)\n",
    "    meeting_days_from_start = dt_to_days(meeting_timedelta_from_start)  #all meeting days from start\n",
    "    \n",
    "    row2_meeting_days_from_start = meeting_days_from_start[~np.isnan(unfiltered_row_2)]\n",
    "    row1_meeting_days_from_start = meeting_days_from_start[~np.isnan(unfiltered_row_1)]\n",
    "    \n",
    "    day_first = 0\n",
    "    day_last_2 = row2_meeting_days_from_start[-1]\n",
    "    day_last_1 = row1_meeting_days_from_start[-1]\n",
    "\n",
    "    #applying curve smoothing\n",
    "    try: \n",
    "        smoothed_2 = CubicSpline(row2_meeting_days_from_start,row_2)\n",
    "        fitted_range_2 = np.linspace(day_first,day_last_2)\n",
    "    except:     #<2 conrtacts available on that day\n",
    "        less_than_two_contracts_2 = True\n",
    "    try:\n",
    "        smoothed_1 = CubicSpline(row1_meeting_days_from_start, row_1)\n",
    "        fitted_range_1 = np.linspace(day_first,day_last_1)\n",
    "    except:\n",
    "        less_than_two_contracts_1 = True\n",
    "\n",
    "    #plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    #plot rates\n",
    "    plt.scatter(x = meeting_days_from_start, y =unfiltered_row_2,label = f'Implied curve on {date_2.date()}')    \n",
    "    plt.scatter(x = meeting_days_from_start, y =unfiltered_row_1,label = f'Implied curve on {date_1.date()}') \n",
    "    #plot interpolated curve \n",
    "    if less_than_two_contracts_2 == False:\n",
    "        plt.plot(fitted_range_2, smoothed_2(fitted_range_2))\n",
    "    if less_than_two_contracts_1 == False:\n",
    "        plt.plot(fitted_range_1, smoothed_1(fitted_range_1))\n",
    "    xticks(meeting_days_from_start, meetings)  # Space out meetings according to time\n",
    "    \n",
    "    plt.title('Historical Implied Fed Funds Rate/bps Across Meetings')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    \n",
    "    #returns data table of all implied rates for different meetings on the two input days \n",
    "    table = pd.DataFrame(np.array([unfiltered_row_1,unfiltered_row_2]),columns = meetings, index = [date_1,date_2])\n",
    "    \n",
    "    return table\n",
    "\n",
    "def plot_historical_curve(meetings_implied_df):\n",
    "    '''\n",
    "    Turn the plotting function from static to interactive\n",
    "    '''\n",
    "    \n",
    "    #Building our Date Slider\n",
    "    start_date = meetings_implied_df.index[0]\n",
    "    end_date = meetings_implied_df.index[-1]\n",
    "    dates = pd.date_range(start_date, end_date, freq='D')\n",
    "    options = [(date.strftime(' %d %b %y '), date) for date in dates]\n",
    "    index = (0, len(options)-1)\n",
    "\n",
    "    selection_range_slider = widgets.SelectionRangeSlider(\n",
    "        options=options,\n",
    "        index=index,\n",
    "        description='Dates',\n",
    "        orientation='horizontal',\n",
    "        layout={'width': '600px'}\n",
    "    )\n",
    "\n",
    "    return widgets.interact(plotting,meetings_implied_df = widgets.fixed(meetings_implied_df),date = selection_range_slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputting some default data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_meetings():\n",
    "    '''\n",
    "    Default meetings are the most recently closed meeting + all future unclosed meetings\n",
    "    '''\n",
    "    actual_FOMC = User.actual_FOMC\n",
    "    most_recent_id_FED = 'FED-'+get_recent_close(User.actual_FOMC)[0]\n",
    "    defaults = [most_recent_id_FED] + unsettled_contracts()\n",
    "    return defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data anomolies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meeting(meeting,lookback):\n",
    "    '''\n",
    "    meeting:a string of the form '23FEB'; lookback: int, # of lookback days(should be same as the one used in plotting)\n",
    "    returns 1 df and 1 dictionary\n",
    "    df1 shows historical prices of all contracts; \n",
    "    dic1 contains more detailed historical data for different specific contracts (output of function build_df_each_rate);\n",
    "    Each df in dic1 has index Time, columns [volume, open_interest, price, spread] \n",
    "    '''\n",
    "    series_id = 'FED-'+meeting   #convert to ideal format\n",
    "   \n",
    "    #get df for the target series_id in order to retrieve all tickers for that meeting\n",
    "    series_content_df = specified_markets(series_ticker= series_id)\n",
    "    #Get dictionary of df for specific strikes\n",
    "    try:\n",
    "        contracts = build_df_each_rate(contract_ids = series_content_df.ticker.tolist(), categories = series_content_df.subtitle.tolist(),lookback = lookback) \n",
    "    except:\n",
    "        raise ValueError(f'Please check your lookback period or meetings are correct!')\n",
    "    \n",
    "    meetings = {}\n",
    "    cum_df = cumulative_df(contracts).iloc[:,::-1]\n",
    "    imp_rates = discrete_df(cum_df,month = series_id[-3:], year =series_id[-5:-3]) #naming the columns\n",
    "    meetings[series_id] = imp_rates\n",
    "    meetings_implied_df_ = pd.concat(meetings.values(),axis = 1).fillna(0)\n",
    "    \n",
    "    cum_df.reset_index(drop = False,inplace = True)\n",
    "    cum_df['Date']=cum_df['Date'].apply(lambda x: x.date())\n",
    "    return cum_df, contracts\n",
    "\n",
    "def check_meeting_ondate(cum_df,year,month,day):\n",
    "    '''\n",
    "    e.g. year = 2022,month = 12,day = 20\n",
    "    returns closing mid prices of all contracts on that date\n",
    "    '''\n",
    "    date_to_check = datetime(year,month,day).date()\n",
    "    return cum_df[cum_df['Date']==date_to_check]\n",
    "\n",
    "def check_raw_data(contracts,strike,year,month,day):\n",
    "    '''\n",
    "    contracts: our dictionary of dfs for different strikes for that meeting\n",
    "    strike: string, '2.00%', obtained by inspecting columns from output of check_meeting_ondate()\n",
    "    returns data on on specific strike contract for our given meeting on our specific date \n",
    "    '''\n",
    "    all_contracts = list(contracts.keys())\n",
    "    \n",
    "    #filter for the index that contains the strike  \n",
    "    #our strike may be'2.00%', yet our contract_index may be '>2.00%'\n",
    "    specific_contract = [x for x in all_contracts if strike in x][0]\n",
    "    raw_data = contracts[specific_contract]\n",
    "    raw_data['Date']=raw_data['Date'].apply(lambda x: x.date())\n",
    "    date_to_check = datetime(year,month,day).date()\n",
    "    row = raw_data[raw_data['Date']==date_to_check]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_prices,contracts = check_meeting('23JUN',lookback = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_meeting_ondate(historical_prices,2022,12,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check_raw_data(contracts, '5.00%').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below for testing output & debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Testing various intermediate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# series_id='FED-23JUN'\n",
    "# lookback_ = 10\n",
    "# series_dfs = {}\n",
    "\n",
    "# #get df for each contract in the series in order to retrieve all tickers for that series\n",
    "# series_content_df = specified_markets(series_ticker= series_id)\n",
    "# #for each series, get dictionary of df for specific contracts\n",
    "# contracts = build_df_each_rate(contract_ids = series_content_df.ticker.tolist(), categories = series_content_df.subtitle.tolist(),lookback = lookback_) \n",
    "# #we put the dictionary into another dictionary\n",
    "# series_dfs[series_id] = contracts\n",
    "    \n",
    "# meetings = {}\n",
    "# cum_df = cumulative_df(contracts).iloc[:,::-1]\n",
    "# imp_rates = discrete_df(cum_df,month = series_id[-3:], year =series_id[-5:-3]) #naming the columns\n",
    "# meetings[series_id] = imp_rates\n",
    "# meetings_implied_df_ = pd.concat(meetings.values(),axis = 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cum_df.reset_index(drop = False,inplace = True)\n",
    "# cum_df['Date']=cum_df['Date'].apply(lambda x: x.date())\n",
    "# cum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# date_to_check = datetime(2022,12,20).date()\n",
    "# cum_df[cum_df['Date']==date_to_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# series_dfs['FED-23FEB']['>2.00%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Testing plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meetings_ = ['FED-23SEP','FED-23NOV']\n",
    "# lookback_ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meetings_implied_df = get_meetings_implied_df(series_ids = meetings_,lookback = lookback_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Plotting dashboard\n",
    "# plot_historical_curve(meetings_implied_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
